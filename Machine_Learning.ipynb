{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy import sparse\n",
    "from sys import getsizeof\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime as dt\n",
    "import meteomatics.api as metapi\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "directory = r\"D:\\Users\\xubil\\OneDrive\\Documents\\Wildfires Data NPZ\"\n",
    "data = {}\n",
    "processed = {}\n",
    "\n",
    "# Get xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "username = 'student_xu_bill'\n",
    "password = '7o7zT54NlW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_zoom(x_min, x_max, y_min, y_max):\n",
    "    ratio_y, ratio_x = (y_max-y_min)/36400, (x_max-x_min)/59700\n",
    "    \n",
    "\n",
    "    for subdir in data:\n",
    "        processed[subdir] = {}\n",
    "\n",
    "        for filename in data[subdir]:\n",
    "\n",
    "            data_process = data[subdir][filename][y_min:y_max, x_min:x_max] # To csc speeds up processing\n",
    "\n",
    "            N, M = data_process.shape\n",
    "            s, t = int(400*ratio_y), int(400*ratio_x)          # decimation factors for y and x directions\n",
    "            T = sparse.csc_matrix((np.ones((M,)), np.arange(M), np.r_[np.arange(0, M, t), M]), (M, (M-1) // t + 1))\n",
    "            S = sparse.csr_matrix((np.ones((N,)), np.arange(N), np.r_[np.arange(0, N, s), N]), ((N-1) // s + 1, N))\n",
    "            result = S @ data_process @ T     # downsample by binning into s x t rectangles\n",
    "            processed[subdir][filename] = result.todense() \n",
    "    \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from  aq_routes_2020_l_arc_f\n",
      "Reading from  bdat_hypso_l_arc\n",
      "Reading from  canards_sauv_mhb_2008_s_poly\n",
      "Reading from  canards_sauv_mhnb_2008_s_poly\n",
      "Reading from  data-npz_bdtq_hydro_s_poly\n",
      "Reading from  dmti_transmissionlines_2021_l_arc\n",
      "Reading from  fires\n",
      "Reading from  Ignore\n",
      "Reading from  mrnf_20k_peu_ecofo_ori_poly_f\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(directory):\n",
    "    print(\"Reading from \",filename)\n",
    "    filedir = os.path.join(directory, filename)\n",
    "    if (filename == \"fires\" or filename == \"Ignore\"):\n",
    "        continue\n",
    "\n",
    "    data[filename] = {}\n",
    "\n",
    "    for npzname in os.listdir(filedir):\n",
    "        # print(npzname)\n",
    "        finaldir = os.path.join(filedir, npzname)\n",
    "        data[filename][npzname] = sparse.load_npz(finaldir).tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
